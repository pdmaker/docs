---
title: '国产大模型使用指南'
description: '通义千问、文心一言、智谱ChatGLM等国产大模型的详细使用指南'
---

# 国产大模型使用指南

中国在人工智能领域发展迅速，涌现出许多优秀的大模型。API易平台集成了主流的国产大模型，包括阿里的通义千问、百度的文心一言、智谱的ChatGLM等，为用户提供丰富的AI能力选择。

## 🚀 支持的国产大模型

<CardGroup cols={2}>
  <Card
    title="通义千问系列"
    icon="alibaba"
    href="#qwen-series"
  >
    阿里巴巴通义千问，强大的中文理解能力
  </Card>
  <Card
    title="文心一言系列"
    icon="baidu"
    href="#ernie-series"
  >
    百度文心一言，领先的中文AI大模型
  </Card>
  <Card
    title="智谱ChatGLM"
    icon="zhipu"
    href="#chatglm-series"
  >
    清华智谱ChatGLM，开源生态的先锋
  </Card>
  <Card
    title="DeepSeek系列"
    icon="deepseek"
    href="#deepseek-series"
  >
    DeepSeek深度求索，优秀的推理能力
  </Card>
</CardGroup>

## 通义千问系列

阿里巴巴的通义千问是国内领先的大语言模型，在中文理解、逻辑推理、创意写作等方面表现出色。

### 🎯 Qwen2.5 (最新版本)

**模型ID：** `qwen-turbo-latest`

**特点：**
- 🧠 强大的中文理解和生成能力
- 💻 优秀的代码生成和调试能力
- 📚 丰富的知识储备
- 🎨 创意写作和内容创作
- 🔍 精准的信息提取和总结

**价格：** 输入 $0.3/1M tokens，输出 $0.6/1M tokens

<CodeGroup>

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://api.apiyi.com/v1"
)

# 基础中文对话
response = client.chat.completions.create(
    model="qwen-turbo-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个专业的中文AI助手，擅长各种任务"
        },
        {
            "role": "user",
            "content": "请介绍一下中国传统文化中的"仁义礼智信"五常思想"
        }
    ],
    max_tokens=1000,
    temperature=0.7
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: 'YOUR_API_KEY',
  baseURL: 'https://api.apiyi.com/v1'
});

const completion = await openai.chat.completions.create({
  model: 'qwen-turbo-latest',
  messages: [
    {
      role: 'system',
      content: '你是一个专业的中文AI助手，擅长各种任务'
    },
    {
      role: 'user',
      content: '请介绍一下中国传统文化中的"仁义礼智信"五常思想'
    }
  ],
  max_tokens: 1000,
  temperature: 0.7
});

console.log(completion.choices[0].message.content);
```

```bash cURL
curl -X POST "https://api.apiyi.com/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "qwen-turbo-latest",
    "messages": [
      {
        "role": "system",
        "content": "你是一个专业的中文AI助手，擅长各种任务"
      },
      {
        "role": "user",
        "content": "请介绍一下中国传统文化中的\"仁义礼智信\"五常思想"
      }
    ],
    "max_tokens": 1000,
    "temperature": 0.7
  }'
```

</CodeGroup>

### 🎨 创意写作示例

通义千问在中文创意写作方面表现突出：

```python
# 古诗词创作
poetry_request = """
请创作一首七言律诗，要求：
1. 主题：描绘江南春色
2. 风格：清新淡雅，意境优美
3. 格律：严格遵循平仄规律
4. 内容：体现春天的生机和美景
5. 情感：表达对自然美景的赞美和内心的宁静

请同时提供创作说明和赏析。
"""

response = client.chat.completions.create(
    model="qwen-turbo-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个精通中国古典诗词的文学家，擅长创作优美的诗词作品"
        },
        {
            "role": "user",
            "content": poetry_request
        }
    ],
    max_tokens=800,
    temperature=0.8
)
```

### 💻 代码生成示例

```python
# 中文编程任务
code_request = """
请用Python实现一个中文词频统计程序，要求：

1. 能够处理中文文本文件
2. 正确分词（考虑中文特点）
3. 统计词频并排序
4. 过滤停用词
5. 支持自定义停用词列表
6. 输出结果到文件
7. 包含详细的中文注释
8. 提供使用示例

请确保代码健壮性良好，能处理各种异常情况。
"""

response = client.chat.completions.create(
    model="qwen-turbo-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个专业的Python开发者，擅长中文文本处理和自然语言处理"
        },
        {
            "role": "user",
            "content": code_request
        }
    ],
    max_tokens=2000,
    temperature=0.3
)
```

### 🏪 Qwen Plus (高级版)

**模型ID：** `qwen-plus-latest`

**特点：**
- 🚀 更强的推理能力
- 📚 更大的知识容量
- 💡 更好的创意表现
- 🎯 更精准的任务执行

**价格：** 输入 $2/1M tokens，输出 $6/1M tokens

### 🔬 Qwen Max (旗舰版)

**模型ID：** `qwen-max-latest`

**特点：**
- 👑 最强的性能表现
- 🧠 顶级的推理能力
- 📖 最丰富的知识体系
- 🎨 最佳的创意生成

**价格：** 输入 $20/1M tokens，输出 $60/1M tokens

## 文心一言系列

百度的文心一言是国内最早商业化的大语言模型之一，在中文理解和生成方面有着深厚的技术积累。

### 🎯 ERNIE-Bot 4.0

**模型ID：** `ernie-bot-4`

**特点：**
- 🧠 强大的中文语言理解能力
- 🔍 精准的信息检索和整合
- 💼 优秀的商业场景应用
- 🎨 丰富的创意内容生成
- 📊 专业的数据分析能力

**价格：** 输入 $0.8/1M tokens，输出 $2/1M tokens

### 📊 商业分析示例

```python
# 商业数据分析
business_data = """
某电商平台2024年Q1数据：
- 总营收：15.6亿元，同比增长23%
- 用户数：1.2亿，同比增长18%
- 客单价：156元，同比增长4%
- 移动端占比：78%
- 一线城市用户占比：35%
- 二三线城市用户占比：65%

主要品类表现：
- 服装：营收占比30%，增长28%
- 电子产品：营收占比25%，增长15%
- 家居用品：营收占比20%，增长35%
- 食品饮料：营收占比15%，增长20%
- 其他：营收占比10%，增长10%

竞争环境：
- 行业平均增长率：20%
- 主要竞争对手A：市场份额28%
- 主要竞争对手B：市场份额25%
- 我们的市场份额：15%

请提供详细的业务分析报告。
"""

response = client.chat.completions.create(
    model="ernie-bot-4",
    messages=[
        {
            "role": "system",
            "content": "你是一个资深的商业分析师，擅长电商行业分析和数据解读"
        },
        {
            "role": "user",
            "content": business_data
        }
    ],
    max_tokens=2000,
    temperature=0.3
)
```

### 🎓 ERNIE-Bot Turbo

**模型ID：** `ernie-bot-turbo`

**特点：**
- ⚡ 快速响应
- 💰 成本优化
- 🎯 日常任务处理
- 📱 移动端适配

**价格：** 输入 $0.8/1M tokens，输出 $2/1M tokens

### 📖 教育应用示例

```python
# 教育内容生成
education_request = """
请为初中生设计一个关于"中国古代四大发明"的教学内容，包括：

1. 学习目标和重点
2. 四大发明的详细介绍
3. 每个发明的历史背景和重要意义
4. 对世界文明的影响
5. 互动式学习活动设计
6. 思考题和讨论题
7. 拓展阅读建议

要求：
- 语言通俗易懂，适合初中生理解
- 内容生动有趣，能激发学习兴趣
- 结构清晰，逻辑性强
- 包含具体的教学建议
"""

response = client.chat.completions.create(
    model="ernie-bot-turbo",
    messages=[
        {
            "role": "system",
            "content": "你是一个优秀的历史教师，擅长设计引人入胜的教学内容"
        },
        {
            "role": "user",
            "content": education_request
        }
    ],
    max_tokens=2000,
    temperature=0.6
)
```

## 智谱ChatGLM系列

清华智谱的ChatGLM是国内开源生态的重要代表，在代码生成、逻辑推理等方面表现优秀。

### 🎯 ChatGLM-4

**模型ID：** `chatglm-4-latest`

**特点：**
- 💻 卓越的代码生成能力
- 🧠 强大的逻辑推理能力
- 🔍 精准的信息抽取能力
- 🎨 良好的创意写作能力
- 📚 丰富的知识问答能力

**价格：** 输入 $0.5/1M tokens，输出 $1.5/1M tokens

### 💻 代码生成示例

```python
# 复杂算法实现
algorithm_request = """
请实现一个高效的中文文本相似度计算算法，要求：

1. 支持多种相似度算法（余弦相似度、编辑距离、语义相似度等）
2. 针对中文特点进行优化
3. 支持批量计算
4. 提供性能优化选项
5. 包含完整的单元测试
6. 详细的API文档
7. 使用示例和性能基准测试

技术要求：
- 使用Python实现
- 支持向量化计算
- 内存使用优化
- 支持多线程处理
- 提供配置选项
"""

response = client.chat.completions.create(
    model="chatglm-4-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个算法专家，擅长自然语言处理和高性能计算"
        },
        {
            "role": "user",
            "content": algorithm_request
        }
    ],
    max_tokens=3000,
    temperature=0.2
)
```

### 📊 ChatGLM-3

**模型ID：** `chatglm-3-6b`

**特点：**
- 🎯 平衡的性能和成本
- 🚀 快速的推理速度
- 💡 适合生产环境
- 📱 资源消耗较低

**价格：** 输入 $0.5/1M tokens，输出 $1.5/1M tokens

### 🔍 数据分析示例

```python
# 数据分析和可视化
data_analysis_request = """
请分析以下用户行为数据，并提供可视化建议：

用户访问数据（最近30天）：
- 总访问量：125万次
- 独立访客：45万人
- 页面浏览量：340万次
- 平均停留时间：3.2分钟
- 跳出率：35%

用户来源分布：
- 搜索引擎：45%
- 社交媒体：25%
- 直接访问：20%
- 其他渠道：10%

设备分布：
- 移动端：65%
- 桌面端：30%
- 平板端：5%

地区分布：
- 一线城市：40%
- 二线城市：35%
- 三线及以下：25%

请提供：
1. 数据深度分析
2. 关键指标解读
3. 用户画像分析
4. 问题识别和建议
5. 数据可视化方案
6. 后续优化策略
"""

response = client.chat.completions.create(
    model="chatglm-3-6b",
    messages=[
        {
            "role": "system",
            "content": "你是一个专业的数据分析师，擅长用户行为分析和数据可视化"
        },
        {
            "role": "user",
            "content": data_analysis_request
        }
    ],
    max_tokens=2000,
    temperature=0.3
)
```

## DeepSeek系列

DeepSeek是专注于推理能力的AI模型，在数学、逻辑推理、代码生成等方面表现优异。

### 🎯 DeepSeek-V3

**模型ID：** `deepseek-chat`

**特点：**
- 🧮 强大的数学推理能力
- 💻 卓越的代码生成能力
- 🔬 优秀的科学计算能力
- 🎯 精准的逻辑推理能力
- 💡 创新的问题解决方案

**价格：** 输入 $0.14/1M tokens，输出 $0.28/1M tokens

### 🧮 数学推理示例

```python
# 复杂数学问题
math_problem = """
请解决以下数学问题：

一个正整数n满足以下条件：
1. n是一个四位数
2. n的各位数字之和等于20
3. n能被7整除
4. n的各位数字都不相同
5. n的千位数字是质数

请找出所有满足条件的n，并详细说明解题过程。

另外，请分析这类问题的一般解法，并提供一个Python程序来验证结果。
"""

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[
        {
            "role": "system",
            "content": "你是一个数学专家，擅长数论和组合数学问题"
        },
        {
            "role": "user",
            "content": math_problem
        }
    ],
    max_tokens=2000,
    temperature=0.1
)
```

### 💻 DeepSeek-Coder

**模型ID：** `deepseek-coder`

**特点：**
- 🚀 专门优化的代码生成
- 🔧 强大的调试能力
- 📚 丰富的编程语言支持
- 🎯 精准的代码理解
- 💡 创新的解决方案

**价格：** 输入 $0.14/1M tokens，输出 $0.28/1M tokens

### 🔧 代码调试示例

```python
# 代码调试和优化
debug_request = """
以下Python代码存在性能问题，请帮助分析和优化：

def find_duplicates(arr):
    duplicates = []
    for i in range(len(arr)):
        for j in range(i + 1, len(arr)):
            if arr[i] == arr[j] and arr[i] not in duplicates:
                duplicates.append(arr[i])
    return duplicates

def remove_duplicates(arr):
    result = []
    for item in arr:
        if item not in result:
            result.append(item)
    return result

def process_data(data):
    # 假设data是一个包含100万个元素的列表
    duplicates = find_duplicates(data)
    clean_data = remove_duplicates(data)
    return clean_data, duplicates

问题：
1. 这段代码在处理大量数据时非常慢
2. 内存使用效率不高
3. 算法复杂度过高

请提供：
1. 性能问题分析
2. 时间复杂度和空间复杂度分析
3. 优化后的代码
4. 性能对比测试
5. 最佳实践建议
"""

response = client.chat.completions.create(
    model="deepseek-coder",
    messages=[
        {
            "role": "system",
            "content": "你是一个高级软件工程师，擅长算法优化和性能调优"
        },
        {
            "role": "user",
            "content": debug_request
        }
    ],
    max_tokens=2000,
    temperature=0.2
)
```

## 其他优秀国产模型

### 🎯 讯飞星火

**模型ID：** `spark-3.5-max`

**特点：**
- 🗣️ 优秀的语音理解能力
- 🎯 专业的教育应用
- 💼 丰富的行业解决方案
- 🔍 精准的信息检索

**价格：** 输入 $2/1M tokens，输出 $6/1M tokens

### 🎯 商汤SenseChat

**模型ID：** `sensechat-5`

**特点：**
- 🖼️ 强大的多模态能力
- 🎨 优秀的创意生成
- 🔬 专业的科研应用
- 💡 创新的解决方案

**价格：** 输入 $1.5/1M tokens，输出 $4.5/1M tokens

### 🎯 昆仑万维天工

**模型ID：** `skywork-xl`

**特点：**
- 🌟 均衡的综合能力
- 💼 适合商业应用
- 🚀 快速的响应速度
- 💰 良好的性价比

**价格：** 输入 $1/1M tokens，输出 $3/1M tokens

## 国产模型的独特优势

### 1. 🇨🇳 中文理解优势

国产大模型在中文理解方面具有天然优势：

```python
# 中文语言理解测试
chinese_language_test = """
请分析以下中文表达的深层含义：

1. "这个人说话很有水平"
2. "他这个人比较实在"
3. "这件事情需要再考虑考虑"
4. "你这个想法很有意思"
5. "我觉得这个方案还可以"

请解释：
- 每句话的表面意思和深层含义
- 中文表达的委婉和含蓄特点
- 在不同语境下的不同理解
- 外国人可能的理解偏差
"""

response = client.chat.completions.create(
    model="qwen-turbo-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个中文语言专家，深刻理解中文的文化内涵"
        },
        {
            "role": "user",
            "content": chinese_language_test
        }
    ],
    max_tokens=1500,
    temperature=0.4
)
```

### 2. 🏮 文化背景理解

```python
# 传统文化解读
culture_analysis = """
请深入分析《红楼梦》中林黛玉的人物形象：

1. 性格特点分析
2. 文学形象的典型性
3. 所体现的传统文化价值观
4. 在现代社会的意义
5. 与西方文学人物的对比

请结合具体的诗词和情节进行分析。
"""

response = client.chat.completions.create(
    model="ernie-bot-4",
    messages=[
        {
            "role": "system",
            "content": "你是一个中国文学研究专家，对古典文学有深入理解"
        },
        {
            "role": "user",
            "content": culture_analysis
        }
    ],
    max_tokens=2000,
    temperature=0.5
)
```

### 3. 🏢 本土化应用

```python
# 本土化商业应用
local_business = """
请为一家中国传统茶叶公司设计数字化转型方案：

公司背景：
- 成立于1920年，百年老字号
- 主营龙井、铁观音、普洱等名茶
- 传统线下销售为主
- 品牌知名度较高，客户群体偏年长

现状挑战：
- 年轻消费者流失
- 线上销售薄弱
- 品牌形象老化
- 竞争激烈

请提供：
1. 数字化转型战略
2. 品牌年轻化方案
3. 线上营销策略
4. 产品创新建议
5. 技术实施路径
6. 风险控制措施

要求结合中国消费者习惯和文化特色。
"""

response = client.chat.completions.create(
    model="chatglm-4-latest",
    messages=[
        {
            "role": "system",
            "content": "你是一个数字化转型专家，深刻理解中国市场和消费者行为"
        },
        {
            "role": "user",
            "content": local_business
        }
    ],
    max_tokens=2500,
    temperature=0.4
)
```

## 使用技巧和最佳实践

### 1. 模型选择策略

<AccordionGroup>
  <Accordion icon="language" title="中文内容创作">
    **推荐模型：**
    - **文学创作**: 通义千问Max, 文心一言4.0
    - **商业文案**: 通义千问Plus, 文心一言Turbo
    - **教育内容**: 文心一言4.0, 讯飞星火
    - **技术文档**: 智谱ChatGLM-4, DeepSeek-V3
    
    ```python
    # 不同场景的模型选择
    model_selection = {
        "poetry": "qwen-max-latest",
        "business": "ernie-bot-4",
        "education": "ernie-bot-turbo",
        "technical": "chatglm-4-latest"
    }
    ```
  </Accordion>

  <Accordion icon="code" title="代码相关任务">
    **推荐模型：**
    - **代码生成**: DeepSeek-Coder, 智谱ChatGLM-4
    - **代码调试**: DeepSeek-Coder, 通义千问Plus
    - **算法设计**: DeepSeek-V3, 智谱ChatGLM-4
    - **技术咨询**: 通义千问Plus, 智谱ChatGLM-4
    
    ```python
    # 代码任务配置
    code_configs = {
        "generation": {
            "model": "deepseek-coder",
            "temperature": 0.2,
            "max_tokens": 2000
        },
        "debug": {
            "model": "deepseek-coder",
            "temperature": 0.1,
            "max_tokens": 1500
        }
    }
    ```
  </Accordion>

  <Accordion icon="brain" title="逻辑推理分析">
    **推荐模型：**
    - **数学推理**: DeepSeek-V3, 智谱ChatGLM-4
    - **逻辑分析**: 通义千问Max, DeepSeek-V3
    - **科学计算**: DeepSeek-V3, 智谱ChatGLM-4
    - **数据分析**: 文心一言4.0, 通义千问Plus
    
    ```python
    # 推理任务配置
    reasoning_configs = {
        "math": {
            "model": "deepseek-chat",
            "temperature": 0.1,
            "max_tokens": 2000
        },
        "logic": {
            "model": "qwen-max-latest",
            "temperature": 0.2,
            "max_tokens": 1500
        }
    }
    ```
  </Accordion>

  <Accordion icon="dollar-sign" title="成本优化场景">
    **推荐模型：**
    - **日常对话**: 通义千问Turbo, 文心一言Turbo
    - **简单任务**: 智谱ChatGLM-3, DeepSeek-V3
    - **批量处理**: 通义千问Turbo, 智谱ChatGLM-3
    - **测试开发**: DeepSeek-V3, 智谱ChatGLM-3
    
    ```python
    # 成本优化配置
    cost_configs = {
        "daily": {
            "model": "qwen-turbo-latest",
            "temperature": 0.7,
            "max_tokens": 500
        },
        "batch": {
            "model": "chatglm-3-6b",
            "temperature": 0.5,
            "max_tokens": 300
        }
    }
    ```
  </Accordion>
</AccordionGroup>

### 2. 中文优化技巧

<CardGroup cols={2}>
  <Card
    title="中文提示词优化"
    icon="language"
  >
    充分利用中文的表达特点
    
    ```python
    # 中文提示词示例
    chinese_prompt = """
    您是一位资深的{领域}专家，具有以下特点：
    - 深厚的专业功底和丰富的实践经验
    - 善于用通俗易懂的语言解释复杂概念
    - 注重理论与实践的结合
    - 具有强烈的责任心和职业操守
    
    请您从专业角度分析以下问题：
    {问题描述}
    
    请按照以下结构回答：
    1. 问题分析
    2. 解决方案
    3. 实施建议
    4. 风险提示
    """
    ```
  </Card>

  <Card
    title="文化背景融入"
    icon="culture"
  >
    结合中国文化背景增强理解
    
    ```python
    # 文化背景示例
    cultural_context = """
    请结合中国传统文化和现代社会特点，
    分析{主题}的发展现状和未来趋势。
    
    分析要点：
    - 传统文化的影响和启示
    - 现代社会的需求和挑战
    - 东西方文化的差异和融合
    - 未来发展的机遇和方向
    """
    ```
  </Card>

  <Card
    title="本土化应用"
    icon="map"
  >
    针对中国市场特点进行优化
    
    ```python
    # 本土化应用示例
    localized_prompt = """
    请为中国市场设计{产品/服务}方案，
    需要考虑：
    
    市场特点：
    - 消费习惯和偏好
    - 文化价值观
    - 监管政策环境
    - 竞争格局
    
    用户群体：
    - 一线城市vs三四线城市
    - 不同年龄段的需求差异
    - 收入水平和消费能力
    """
    ```
  </Card>

  <Card
    title="语言风格适配"
    icon="pen"
  >
    根据目标用户调整语言风格
    
    ```python
    # 语言风格配置
    style_configs = {
        "formal": "请使用正式、专业的语言风格",
        "casual": "请使用轻松、友好的语言风格",
        "academic": "请使用严谨、学术的语言风格",
        "creative": "请使用生动、有趣的语言风格"
    }
    ```
  </Card>
</CardGroup>

### 3. 性能优化实践

```python
class ChineseModelOptimizer:
    """国产模型优化器"""
    
    def __init__(self, default_model="qwen-turbo-latest"):
        self.client = OpenAI(
            api_key="YOUR_API_KEY",
            base_url="https://api.apiyi.com/v1"
        )
        self.default_model = default_model
        self.model_routing = {
            "creative": "qwen-max-latest",
            "analytical": "ernie-bot-4",
            "coding": "deepseek-coder",
            "reasoning": "deepseek-chat",
            "general": "qwen-turbo-latest"
        }
    
    def select_model(self, task_type: str, complexity: str = "medium"):
        """智能模型选择"""
        base_model = self.model_routing.get(task_type, self.default_model)
        
        if complexity == "high":
            # 使用更强的模型
            model_upgrades = {
                "qwen-turbo-latest": "qwen-plus-latest",
                "ernie-bot-turbo": "ernie-bot-4",
                "chatglm-3-6b": "chatglm-4-latest"
            }
            return model_upgrades.get(base_model, base_model)
        elif complexity == "low":
            # 使用更经济的模型
            model_downgrades = {
                "qwen-plus-latest": "qwen-turbo-latest",
                "ernie-bot-4": "ernie-bot-turbo",
                "chatglm-4-latest": "chatglm-3-6b"
            }
            return model_downgrades.get(base_model, base_model)
        
        return base_model
    
    def optimize_prompt(self, prompt: str, task_type: str):
        """中文提示词优化"""
        optimizations = {
            "creative": "请发挥您的创意和想象力，",
            "analytical": "请运用您的分析能力，深入思考",
            "coding": "请作为一名资深程序员，",
            "reasoning": "请运用逻辑推理和数学思维，",
            "general": "请仔细思考并"
        }
        
        prefix = optimizations.get(task_type, "请")
        return f"{prefix}{prompt}"
    
    def batch_process(self, tasks: list, task_type: str = "general"):
        """批量处理任务"""
        results = []
        model = self.select_model(task_type)
        
        for task in tasks:
            optimized_prompt = self.optimize_prompt(task, task_type)
            
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {
                            "role": "user",
                            "content": optimized_prompt
                        }
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                
                results.append({
                    "task": task,
                    "result": response.choices[0].message.content,
                    "model": model
                })
                
            except Exception as e:
                results.append({
                    "task": task,
                    "error": str(e),
                    "model": model
                })
        
        return results

# 使用示例
optimizer = ChineseModelOptimizer()

# 批量处理不同类型的任务
creative_tasks = [
    "写一首关于春天的现代诗",
    "创作一个科幻短故事",
    "设计一个创意广告文案"
]

analytical_tasks = [
    "分析当前房地产市场趋势",
    "评估新能源汽车发展前景",
    "研究人工智能的社会影响"
]

creative_results = optimizer.batch_process(creative_tasks, "creative")
analytical_results = optimizer.batch_process(analytical_tasks, "analytical")
```

### 4. 错误处理和监控

```python
import logging
from typing import Dict, Any, Optional

class ChineseModelMonitor:
    """国产模型监控器"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.usage_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_tokens": 0,
            "model_usage": {}
        }
    
    def log_request(self, model: str, prompt: str, response: Optional[str], 
                   error: Optional[str] = None):
        """记录请求日志"""
        self.usage_stats["total_requests"] += 1
        
        if error:
            self.usage_stats["failed_requests"] += 1
            self.logger.error(f"Model {model} failed: {error}")
        else:
            self.usage_stats["successful_requests"] += 1
            self.logger.info(f"Model {model} succeeded")
            
            # 统计token使用
            estimated_tokens = len(prompt) + len(response or "")
            self.usage_stats["total_tokens"] += estimated_tokens
            
            # 统计模型使用情况
            if model not in self.usage_stats["model_usage"]:
                self.usage_stats["model_usage"][model] = 0
            self.usage_stats["model_usage"][model] += 1
    
    def get_stats(self) -> Dict[str, Any]:
        """获取统计信息"""
        success_rate = (self.usage_stats["successful_requests"] / 
                       max(self.usage_stats["total_requests"], 1)) * 100
        
        return {
            "success_rate": f"{success_rate:.2f}%",
            "total_requests": self.usage_stats["total_requests"],
            "total_tokens": self.usage_stats["total_tokens"],
            "model_usage": self.usage_stats["model_usage"]
        }
    
    def recommend_optimization(self) -> str:
        """推荐优化建议"""
        stats = self.get_stats()
        success_rate = float(stats["success_rate"].rstrip('%'))
        
        if success_rate < 90:
            return "建议检查网络连接和API密钥配置"
        elif stats["total_tokens"] > 1000000:
            return "建议优化提示词长度和使用更经济的模型"
        else:
            return "当前使用状况良好"

# 使用示例
monitor = ChineseModelMonitor()

# 在API调用中集成监控
def monitored_api_call(model: str, prompt: str):
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000
        )
        
        result = response.choices[0].message.content
        monitor.log_request(model, prompt, result)
        return result
        
    except Exception as e:
        monitor.log_request(model, prompt, None, str(e))
        raise e

# 查看统计信息
stats = monitor.get_stats()
print(f"使用统计: {stats}")
print(f"优化建议: {monitor.recommend_optimization()}")
```

---

<CardGroup cols={2}>
  <Card
    title="了解更多集成方案"
    icon="plug"
    href="/api-reference/applications"
  >
    查看如何将国产模型集成到第三方应用中
  </Card>
  <Card
    title="查看完整API文档"
    icon="book"
    href="/api-reference/introduction"
  >
    了解所有API调用方法和参数说明
  </Card>
</CardGroup> 